
## 认识HMM与CRF模型

---

### 学习目标

* 了解HMM与CRF模型的输入和输出.
* 了解HMM与CRF模型的作用.
* 了解HMM与CRF模型的使用过程.
* 了解HMM与CRF模型之间的差异.
* 了解HMM和CRF的发展现状.

---

### 1.HMM

#### 1.1 HMM模型的输入和输出

* HMM(Hidden Markov Model), 中文称作隐含马尔科夫模型, 因俄国数学家马尔可夫而得名. 它一般以文本序列数据为输入, 以该序列对应的隐含序列为输出.

---

* 什么是隐含序列:
	* 序列数据中每个单元包含的隐性信息, 这些隐性信息之间也存在一定关联. 

---

* 举个栗子:

```text
给定一段文本: "人生该如何起头"

我们看到的这句话可以叫做: 观测序列

我们可以将这句话以词为单位进行划分得到:

["人生", "该", "如何", "起头"]

那么每个词对应的词性就是它的隐含序列, 如: 

["n", "r", "r", "v"]
```

---

#### 1.2 HMM模型的作用

* 在NLP领域, HMM用来解决文本序列标注问题. 如分词, 词性标注, 命名实体识别都可以看作是序列标注问题.

---

#### 1.3 HMM模型使用过程简述

* 首先, HMM模型表示为: lambda = HMM(A, B, pi), 其中A, B, pi都是模型的参数, 分别称作: 转移概率矩阵, 发射概率矩阵和初始概率矩阵.
* 接着, 我们开始训练HMM模型, 语料就是事先准备好的一定数量的观测序列及其对应的隐含序列, 通过极大似然估计求得一组参数, 使由观测序列到对应隐含序列的概率最大.
* 在训练过程中, 为了简化计算, 马尔可夫提出一种假设: 隐含序列中每个单元的可能性只与上一个单元有关. 这个假设就是著名的隐含假设.
* 训练后, 我们就得到了具备预测能力的新模型: lambda = HMM(A, B, pi), 其中的模型参数已经改变. 
* 之后给定输入序列(x1, x2, ..., xn), 经过模型计算lambda(x1, x2, ..., xn)得到对应隐含序列的条件概率分布.
* 最后, 使用维特比算法从隐含序列的条件概率分布中找出概率最大的一条序列路径就是我们需要的隐含序列: (y1, y2, ..., yn). 

---



### 2.CRF

#### 2.1 CRF模型的输入和输出

* CRF(Conditional Random Fields), 中文称作条件随机场, 同HMM一样,  它一般也以文本序列数据为输入, 以该序列对应的隐含序列为输出.

---

#### 2.2 CRF模型的作用

* 同HMM一样, 在NLP领域, CRF用来解决文本序列标注问题. 如分词, 词性标注, 命名实体识别.

---

#### 2.3 CRF模型使用过程简述

* 首先, CRF模型表示为: lambda = CRF(w1, w2, ..., wn), 其中w1到wn是模型参数.
* 接着, 我们开始训练CRF模型, 语料同样是事先准备好的一定数量的观测序列及其对应的隐含序列.
* 与此同时我们还需要做人工特征工程, 然后通过不断训练求得一组参数, 使由观测序列到对应隐含序列的概率最大.
* 训练后, 我们就得到了具备预测能力的新模型: lambda = CRF(w1, w2, ..., wn), 其中的模型参数已经改变.
* 之后给定输入序列(x1, x2, ..., xn), 经过模型计算lambda(x1, x2, ..., xn)得到对应隐含序列的条件概率分布.
* 最后, 还是使用维特比算法从隐含序列的条件概率分布中找出概率最大的一条序列路径就是我们需要的隐含序列: (y1, y2, ..., yn).

---

### 3.模型之间对比

#### 3.1 HMM与CRF模型之间差异

* HMM模型存在隐马假设, 而CRF不存在, 因此HMM的计算速度要比CRF模型快很多, 适用于对预测性能要求较高的场合.
* 同样因为隐马假设, 当预测问题中隐含序列单元并不是只与上一个单元有关时, HMM的准确率会大大降低, 而CRF不受这样限制, 准确率明显高于HMM.

---

#### 3.2 HMM和CRF的发展现状

* HMM和CRF模型曾在多种序列任务中表现出色, 伴随NLP工程师度过漫长的一段时期.
* 但由于近年来深度学习发展迅速, 经典序列模型, 如HMM和CRF, 已经开始慢慢淡出人们的视野. 
* 因此, 我们这里也是对其做了简洁的总结知识, 让大家对其有一定的基本认识.

#### 3.3 对比（HMM & MEMM & CRF）

```text
HMM vs. MEMM(最大熵马尔可夫) vs. CRF
将三者放在一块做一个总结：

HMM -> MEMM： HMM模型中存在两个假设：一是输出观察值之间严格独立，二是状态的转移过程中当前状态只与前一状态有关。
但实际上序列标注问题不仅和单个词相关，而且和观察序列的长度，单词的上下文，等等相关。
MEMM解决了HMM输出独立性假设的问题。因为HMM只限定在了观测与状态之间的依赖，
而MEMM引入自定义特征函数，不仅可以表达观测之间的依赖，还可表示当前观测与前后多个状态之间的复杂依赖。
MEMM -> CRF:
CRF不仅解决了HMM输出独立性假设的问题，还解决了MEMM的标注偏置问题，
MEMM容易陷入局部最优是因为只在局部做归一化，而CRF统计了全局概率，在做归一化时考虑了数据在全局的分布，而不是仅仅在局部归一化，
这样就解决了MEMM中的标记偏置的问题。使得序列标注的解码变得最优解。

HMM、MEMM属于有向图，所以考虑了x与y的影响，但没讲x当做整体考虑进去（这点问题应该只有HMM）。CRF属于无向图，没有这种依赖性，克服此问题。
```

---

## 4.模型溯源
- 他们都属于概率图模型，具体可以参考下图：
<img width="652" alt="image" src="https://github.com/sherwinNG/budao_AI/assets/52407961/5b17222f-9711-4824-a1a0-495002623686">


### 4.小节总结

* 学习了HMM与CRF模型的输入和输出.
* 学习了HMM与CRF模型的作用.
* 学习了HMM与CRF模型的使用过程.
* 学习了HMM与CRF模型之间的差异.
* 学习了HMM和CRF的发展现状.

---
